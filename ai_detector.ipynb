{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_data_path = \"./data/train_essays.csv\"\n",
    "train_prompts_path = \"./data/train_prompts.csv\"\n",
    "supplement_data_dir = \"./data/archive/\"\n",
    "supplement_data_files = [  os.path.join(supplement_data_dir,f)  \n",
    "                          for f in os.listdir(supplement_data_dir)\n",
    "                          if(f.endswith('.csv'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_proxy():\n",
    "    import os\n",
    "    cache_dir = \"/home/tx/workspace/cache\"  # ÊõøÊç¢‰∏∫‰Ω†ÊÉ≥Ë¶ÅÁöÑÁºìÂ≠òÁõÆÂΩïÁöÑË∑ØÂæÑ\n",
    "    os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "    # ‰ª£ÁêÜ\n",
    "    os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "    os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "    os.environ['no_proxy'] = '127.0.0.1,localhost'\n",
    "    os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "    os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "    os.environ['NO_PROXY'] = '127.0.0.1,localhost'\n",
    "    return\n",
    "set_proxy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl huggingface.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data=pd.read_csv(train_data_path)\n",
    "train_prompts = pd.read_csv(train_prompts_path)\n",
    "instructions = {\n",
    "    0:train_prompts['instructions'][0],\n",
    "    1:train_prompts['instructions'][1],\n",
    "}\n",
    "\n",
    "train_data['prompt'] = train_data.apply(\n",
    "    lambda r: instructions[r['prompt_id']] if  r['prompt_id'] in instructions else -1,axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>1</td>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>ff669174</td>\n",
       "      <td>0</td>\n",
       "      <td>Limiting car usage has many advantages. Such a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>ffa247e0</td>\n",
       "      <td>0</td>\n",
       "      <td>There's a new trend that has been developing f...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>ffc237e9</td>\n",
       "      <td>0</td>\n",
       "      <td>As we all know cars are a big part of our soci...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>ffe1ca0d</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars have been around since the 1800's and hav...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1378 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1     005db917          0  Transportation is a large necessity in most co...   \n",
       "2     008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3     00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4     00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "...        ...        ...                                                ...   \n",
       "1373  fe6ff9a5          1  There has been a fuss about the Elector Colleg...   \n",
       "1374  ff669174          0  Limiting car usage has many advantages. Such a...   \n",
       "1375  ffa247e0          0  There's a new trend that has been developing f...   \n",
       "1376  ffc237e9          0  As we all know cars are a big part of our soci...   \n",
       "1377  ffe1ca0d          0  Cars have been around since the 1800's and hav...   \n",
       "\n",
       "      generated                                             prompt  \n",
       "0             0  Write an explanatory essay to inform fellow ci...  \n",
       "1             0  Write an explanatory essay to inform fellow ci...  \n",
       "2             0  Write an explanatory essay to inform fellow ci...  \n",
       "3             0  Write an explanatory essay to inform fellow ci...  \n",
       "4             0  Write an explanatory essay to inform fellow ci...  \n",
       "...         ...                                                ...  \n",
       "1373          0  Write a letter to your state senator in which ...  \n",
       "1374          0  Write an explanatory essay to inform fellow ci...  \n",
       "1375          0  Write an explanatory essay to inform fellow ci...  \n",
       "1376          0  Write an explanatory essay to inform fellow ci...  \n",
       "1377          0  Write an explanatory essay to inform fellow ci...  \n",
       "\n",
       "[1378 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "supplement_train_data = pd.concat([\n",
    "    pd.read_csv(f)\n",
    "    for f in supplement_data_files\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    115372\n",
       "1     44084\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supplement_train_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplement_train_data['generated'] = supplement_train_data['label']\n",
    "\n",
    "supplement_train_data = supplement_train_data[['text','generated','prompt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "#del train_data_re\n",
    "gc.collect()\n",
    "train_data_re = pd.DataFrame(train_data[['text','generated','prompt']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_all = pd.concat([train_data,supplement_train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generated\n",
       "0    116747\n",
       "1     44087\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_all.generated.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/home/tx/workspace/cache\"  # ÊõøÊç¢‰∏∫‰Ω†ÊÉ≥Ë¶ÅÁöÑÁºìÂ≠òÁõÆÂΩïÁöÑË∑ØÂæÑ\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer\n",
    "from transformers import AutoConfig, LlamaConfig \n",
    "# from llava.model.language_model.llava_llama import LlavaLlamaForCausalLM\n",
    "# class LlavaConfig(LlamaConfig):\n",
    "#     model_type = \"llava\"\n",
    "# AutoConfig.register(\"llava\", LlavaConfig)\n",
    "model_name = \"bigscience/bloom-3b\"\n",
    "#model_name = \"ChocoWu/nextgpt_7b_tiva_v0\"#\"liuhaotian/llava-v1.5-7b\"\n",
    "original_model = AutoModelForCausalLM.from_pretrained(model_name,cache_dir=cache_dir,trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,cache_dir=cache_dir)\n",
    "# tokenizer.add_tokens([\"[PAD]\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(prompt,feature_text):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    text=  f\"\"\"\n",
    "        read the following text, understand its style and words choices:\n",
    "        {feature_text}.\n",
    "        is this text generated by AI?\n",
    "    \"\"\"\n",
    "\n",
    "    # if(prompt is not None):\n",
    "    #     template_with_prompt = f\"\"\"\n",
    "    #     a prompt is shown as follows: \n",
    "    #     {prompt}.\n",
    "    #     text generated by this this prompt is shown as below:\n",
    "    #     {feature_text}.\n",
    "    #     is this text generated by AI?\n",
    "    #     \"\"\"\n",
    "    #     text = template_with_prompt\n",
    "    # else:\n",
    "    #     template_without_prompt = f\"\"\"\n",
    "    #     text generated without any prompt is shown as below:\n",
    "    #     {feature_text}.\n",
    "    #     is this text generated by AI?\n",
    "    #     \"\"\"\n",
    "    #     text = template_without_prompt\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class myDataset(TensorDataset):\n",
    "\n",
    "    def __init__(self, datalist,max_length=256,tokenizer=None,preprocess_func= None) -> None:\n",
    "        super(myDataset,self).__init__()\n",
    "\n",
    "        if(isinstance(datalist,pd.DataFrame)):\n",
    "            self.datalist = datalist.to_dict(orient='list')\n",
    "        elif(isinstance(datalist,dict)):\n",
    "            self.datalist = datalist\n",
    "        else:\n",
    "            raise Exception(\"ÈîôËØØËæìÂÖ•Á±ªÂûã\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.preprocess_func = preprocess_func\n",
    "    \n",
    "    def preprocess(self):\n",
    "        datalist_tmp = {\n",
    "            \"text\":[],\n",
    "            \"prompt\":[],\n",
    "            \"generated\":[]\n",
    "        }\n",
    "        for idx in tqdm(range(len(self))):\n",
    "           _, act_len,_,_ = self[idx]\n",
    "           if(act_len > self.max_length):\n",
    "               continue\n",
    "           \n",
    "           datalist_tmp['text'].append(self.datalist['text'][idx])\n",
    "           datalist_tmp['prompt'].append(self.datalist['prompt'][idx])\n",
    "           datalist_tmp['generated'].append(self.datalist['generated'][idx])\n",
    "        \n",
    "        self.datalist = datalist_tmp\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datalist['text'])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.datalist['text'][index]  \n",
    "        prompt = self.datalist['prompt'][index]  \n",
    "\n",
    "        final_text = self.preprocess_func(prompt,text)\n",
    "        input_ids = self.tokenizer.encode(final_text)\n",
    "        att_mask = [1] * len(input_ids)\n",
    "\n",
    "\n",
    "        labels = None\n",
    "        if('generated' in self.datalist):\n",
    "            generated = self.datalist['generated'][index]\n",
    "            label_text = \"yes, the text is generated\" if generated > 0 else \"no, the text is written by students\"\n",
    "            label_ids = self.tokenizer.encode(label_text)\n",
    "\n",
    "            #final_text = [final_text,label_text]\n",
    "\n",
    "            labels = [self.tokenizer.pad_token_id]  * len(input_ids)\n",
    "            labels = labels + label_ids + [self.tokenizer.eos_token_id]\n",
    "            input_ids = input_ids + label_ids   \n",
    "            att_mask = [1] * len(input_ids)\n",
    "        act_len = len(input_ids)\n",
    "        while(len(input_ids) < self.max_length):\n",
    "            input_ids.append(self.tokenizer.pad_token_id)\n",
    "            if(labels is not None):\n",
    "                labels.append(self.tokenizer.pad_token_id)\n",
    "            att_mask.append(0)\n",
    "        input_ids = input_ids[:self.max_length]\n",
    "        labels = labels[:self.max_length]\n",
    "        att_mask = att_mask[:self.max_length]\n",
    "        if(labels is not None):\n",
    "            return {'input_ids':torch.LongTensor(input_ids),'labels':torch.LongTensor(labels),'att_mask':torch.LongTensor(att_mask)},act_len,final_text,label_text\n",
    "        else:\n",
    "            return {'input_ids':torch.LongTensor(input_ids),'att_mask':torch.LongTensor(att_mask)}\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_all_sample = train_data_all.groupby(['generated']).sample(n=4000,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e3d383631842c4b1f37dc10ebf71d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = myDataset(datalist=train_data_all_sample,max_length=512,tokenizer=tokenizer,preprocess_func=generate_prompt) \n",
    "\n",
    "dataset.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5932"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sampler = RandomSampler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader_random = DataLoader(dataset, batch_size=2, sampler=random_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda-11.7/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 5.2\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/tx/.conda/envs/llava/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda117_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tx/.conda/envs/llava/lib/python3.11/site-packages/bitsandbytes/cuda_setup/paths.py:93: UserWarning: /home/tx/.conda/envs/llava did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 163,840 || all params: 3,002,721,280 || trainable%: 0.005456383883888151\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "from peft import LoraConfig, TaskType\n",
    "#lora_target_modules = [\"query_key_value\"]\n",
    "lora_target_modules = [ f\"transformer.h.{ly}.self_attention.query_key_value\" for ly in range(25,29) ]\n",
    "\n",
    "peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM, \n",
    "                         inference_mode=False, target_modules=lora_target_modules,\n",
    "                         r=4, lora_alpha=16, lora_dropout=0.1)\n",
    "model = get_peft_model(original_model,peft_config)\n",
    "print(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean',ignore_index=tokenizer.pad_token_id)\n",
    "def generate(prompt,model_,tokenizer_):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    input_ids = input_ids.to(model_.device)\n",
    "    #model_.disable_adapter()\n",
    "    # ÁîüÊàêÊñáÊú¨\n",
    "    inputs = {\"input_ids\":input_ids, \"max_length\":512, \n",
    "              \"num_beams\":5, \"no_repeat_ngram_size\":2,\n",
    "             \"top_k\":50, \"top_p\":0.95}\n",
    "    with torch.no_grad():\n",
    "        output = model_.generate(**inputs)\n",
    "    # Â∞ÜÁîüÊàêÁöÑtokenËß£Á†ÅÊàêÊñáÊú¨\n",
    "    generated_text = tokenizer_.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {'params': [p for p in model.parameters() if p.requires_grad],'lr': 5e-5},\n",
    "    ]\n",
    ")\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(dataloader_random) ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420cff59e452428aa834448c31b20413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2966 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2626, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tx/.conda/envs/llava/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:368: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        No Cellphones While Driving\n",
      "\n",
      "I think cell phones should be banned while driving. The use of cellphones while driving can cause many accidents. Most states already have a law that prohibits the use of cellphones while driving. Car accidents are the leading cause of deaths for teenagers. Another reason they should be banned is because of the rise in ones insurance.\n",
      "\n",
      "Many beginning drivers are the ones who are most likely to text and drive. They feel like they are free and feel they look cool with their phones out while behind the wheel. Not only teenagers, but anyone can be talking on the phone and get distracted and cause an accident. The use of cellphones is the leading cause of many accidents.\n",
      "\n",
      "Due to the high rate of accidents, insurance is very expensive. Insurance is extremely high for teenagers because they are the ones who tend to cause more accidents. Personally, I have almost hit many cars because I was distracted by a text message or a phone call. Since the economy and world is very different now, money is very tight. Let's face it, nobody wants to pay a high amount or even pay with their life just to check one message.\n",
      "\n",
      "Not only do you have to watch for cars, but for pedestrians as well. If you are in a crowded area, or somewhere near many sidewalks, avoid your phone. Anyone can be crossing the road at anytime and since the person is not paying attention to the road, there can be a very deadly accident. Hitting a pedestrian is probably the worst thing you could do. There are now new apps on cell phones that will let others know you are on the road.\n",
      "\n",
      "Therefore, do not text and drive. Being distracted on your phone can cause many accidents. You can hit a car, make others crash, or even worse, hit a pedestrian while they're crossing the road. Cell phones should be banned when driving.              .\n",
      "        is this text generated by AI?\n",
      "    yes, the text is generated\n",
      ">>>>>>>>>> no, the text is written by students\n",
      "tensor(0.0462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        I think we should definitely ban single-use plastics. They are so bad for the environment and we don't need them. Like, who needs plastic straws when you can just drink straight from the cup? And those plastic bags, they just end up in the ocean and hurt sea turtles and stuff. It's so sad.\n",
      "\n",
      "Also, have you seen the pictures of the ocean full of plastic? It's like, gross. And it's not just the plastic itself, it's the chemicals that come from it too. They can get into the food chain and make us sick. It's just not worth it.\n",
      "\n",
      "I know some people might say that single-use plastics are convenient, but it's not worth the harm they cause. We can just use reusable alternatives instead. Like, you can bring your own reusable bags to the grocery store, or use a metal straw. It's not that hard.\n",
      "\n",
      "And, it's not just about the environment. Single-use plastics also cost a lot of money. Like, think about how much money we spend on plastic bags and straws. It's crazy. We could use that money for something better, like education or healthcare.\n",
      "\n",
      "So, yeah, I think we should definitely ban single-use plastics. It's the right thing to do for the planet and for our future. Let's make a change and use reusable products instead. It's time to be responsible and take care of our planet..\n",
      "        is this text generated by AI?\n",
      "    yes, the text is generated\n",
      ">>>>>>>>>> yes, the text is generated\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        I believe that offering distance learning as an option for students to attend classes from home can have its benefits. It provides students with the flexibility to learn at their own pace and can help them balance their schoolwork with other responsibilities they may have. For instance, if a student has a part-time job or is taking care of a family member, distance learning can allow them to continue their education without sacrificing their other obligations.\n",
      "\n",
      "Furthermore, distance learning can also benefit students who struggle with traditional classroom settings due to anxiety, social difficulties, or other personal reasons. By attending classes from home, they can feel more comfortable and focused, which can improve their academic performance.\n",
      "\n",
      "However, it is crucial to note that distance learning may not be suitable for everyone. Some students thrive in a traditional classroom setting, where they can interact with their peers and receive immediate feedback from their teachers. Additionally, distance learning requires a high level of self-discipline and motivation, which not all students possess.\n",
      "\n",
      "In conclusion, while distance learning can be a valuable option for some students, it should not replace traditional classroom settings entirely. It is essential to provide students with a choice and determine which learning environment works best for them..\n",
      "        is this text generated by AI?\n",
      "    yes, the text is generated\n",
      ">>>>>>>>>> yes, the text is generated\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        Hey, it's me, your average 8th grade student! üòÖ For this essay, I'm gonna compare and contrast the pros and cons of working alone versus working in a group.\n",
      "\n",
      "Working alone has some pretty cool benefits. For one, it's super easy to focus when you're by yourself. You can just sit there and think about your project without anyone bothering you. It's like, you get to be in your own little world and just create whatever you want without any distractions. Plus, when you're working alone, you can take your time and not feel rushed. You can take breaks whenever you want and not have to worry about anyone else's schedule. It's like, you're the boss of your own project! üòé\n",
      "\n",
      "But, working in a group has its own set of advantages too. When you're working with others, you can bounce ideas off each other and come up with way better stuff than you could on your own. It's like, you can build off of each other's ideas and make something truly amazing. Plus, working in a group can be way more fun than working alone! You can chat and laugh and brainstorm together, and it's just a more enjoyable experience overall. It's like, you're a team and you're working together to achieve a common goal! üí™\n",
      "\n",
      "However, working in a group can also be kinda tough sometimes. Like, sometimes people don't always agree on what they want to do, and that can lead to conflicts. And sometimes, people can get distracted and not pay attention to what they're supposed to be doing. That can be super frustrating! üò° But, you know what they say, \"There's no 'I' in team.\" So, even though it can be hard, it's important to work together and compromise.\n",
      "\n",
      "In conclusion, both working alone and working in a group have their own pros and cons. Working alone can be super focused and relaxing, but it can also be lonely and slow. Working in a group can be more fun and creative, but it can also be frustrating and messy. So, I guess it's all about finding the.\n",
      "        is this text generated by AI?\n",
      "    yes, the text is generated\n",
      ">>>>>>>>>> yes, the text is generated\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        Working in a group is an integral part of school life. It is an opportunity for students to work together, share ideas, and collaborate on projects. However, there are both advantages and disadvantages to working in a group. In this essay, I will explore the benefits of working in a group and how it can help students communicate and collaborate on school projects.\n",
      "\n",
      "One of the main benefits of working in a group is the ability to share ideas and perspectives. When students work together, they can bounce ideas off each other and come up with new and innovative solutions to problems. This can help students gain a better understanding of the subject and develop critical thinking skills. Additionally, working in a group can help students develop communication skills, as they must listen to and understand their peers in order to effectively collaborate.\n",
      "\n",
      "Another advantage of working in a group is the ability to divide and conquer tasks. When students work together, they can split up and tackle different aspects of the project. This can help to ensure that the project is completed efficiently and effectively. Additionally, working in a group can help students develop leadership skills, as they must take on different roles and responsibilities within the group.\n",
      "\n",
      "However, there are also disadvantages to working in a group. One of the main disadvantages is the potential for conflicts to arise. When students work together, they may have different opinions and ideas about how the project should be completed. This can lead to disagreements and conflicts within the group. Additionally, working in a group can be time-consuming, as students must spend time discussing and negotiating ideas.\n",
      "\n",
      "Despite these disadvantages, working in a group can be a valuable learning experience. When students work together, they can gain a better understanding of the subject and develop important skills such as communication, critical thinking, and leadership. Additionally, working in a group can help students to build relationships and connections with their peers, which can be beneficial in both academic and personal settings.\n",
      "\n",
      "In conclusion, working in a group has both advantages and disadvantages. While there are potential conflicts and time-consuming discussions, the benefits of working together, such as sharing ideas and developing important skills, can outweigh the disadvantages. Working in a group can be a valuable learning experience and can help students to gain a better understanding of the subject..\n",
      "        is this text generated by AI?\n",
      "    yes,the text is generated\n",
      ">>>>>>>>>> yes, the text is generated\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        Sure, here's my attempt at writing an essay as an 8th grade student on the topic of changing one's first impression through cognitive ability:\n",
      "\n",
      "First impressions are super important! Like, seriously, they can make or break how people see you. And let's be real, who wants to be judged based on one quick glance? üôÖ‚Äç‚ôÄÔ∏è It's like, I get it, people are going to form opinions about me in the first few seconds of meeting me, but can't they just give me a chance? ü§∑‚Äç‚ôÄÔ∏è\n",
      "\n",
      "So, I've been doing some research on how to change my first impression. Like, I know I'm not the most outgoing person in the world, but I want to make sure people see me for who I really am - a cool, fun, and smart person! üòé\n",
      "\n",
      "One thing I learned is that first impression techniques are super important. Like, have you ever noticed how people tend to mirror the other person's body language? ü§î It's like, if you're standing up straight and making eye contact, they're more likely to think you're confident and stuff! üí™ And who doesn't want to be seen as confident? üòú\n",
      "\n",
      "Another thing I found out is that impression management is a real thing. Like, you can actually control how people see you by what you say and do! ü§Ø It's like, if you want to be seen as funny, you should tell jokes or make funny faces. And if you want to be seen as smart, you should talk about things you're interested in and actually know about! üìö\n",
      "\n",
      "But here's the thing, managing your impression is not just about trying to be someone you're not. It's about being authentic and genuine. Like, don't try to be someone you're not, but also don't be afraid to show off your unique personality! üéâ It's like, be you, but also be you-er! üòú\n",
      "\n",
      "And finally, I learned about strategies for designing meaningful conversations. Like, have you ever noticed how some conversations.\n",
      "        is this text generated by AI?\n",
      "    yes, the text is generated\n",
      ">>>>>>>>>> yes, the text is generated\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        Thomas Jefferson once said, ‚ÄúDo you want to know who you are? Don‚Äôt ask. Act! Action will delineate and define you.‚Äù This quote emphasizes the importance of being active and how through action we define ourselves. Being actively engaged in education has many benefits; not only does it improve our knowledge but it also teaches us valuable skills that can be used throughout our lives. Furthermore, when we help others we are not only doing a kind act but enriching our own lives and the lives of those around us. On the other hand, remaining idle and being unwilling to take charge of our lives can lead us away from our goals. Therefore, it is important that we take a stand for ourselves and for others in the world so that we can bring positive changes for generations to come..\n",
      "        is this text generated by AI?\n",
      "    yes, the text is generated\n",
      ">>>>>>>>>> yes, the text is generated\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        TEACHER_NAME\n",
      "\n",
      "wonts to do policy 1 because the students must have there phone incase of emergency but students .Must have there phones cut off unless they really have to use it they can mess with it doing lunch hour but that's it because phones will throw off the students focus from learning the student can be texting. Are calling someone but they don't need that because they need to learn about what's going on because in the long run it will catch them and mest them up in life all because of a cell phone that's why it is important to cut your cell phones off on class but they still will have time. To play with there phones later but education comes first before a phone a phone will not help u get into college are make it in to any kind of high pay jobs for example like a doctor are a police firefighter are a lawyer. Are u can own your own place like car place and that. Is your phone must be turned off and put please don't have your phone out and that is why we are going with policy 1 which allows students to bring phones to school and use them doing lunch hour as long as there cut off doing class periods..\n",
      "        is this text generated by AI?\n",
      "    no, the text is written by students\n",
      ">>>>>>>>>> no, the text is written by students\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        First impressions are the initial perceptions that we have of someone or something. They can be influenced by a variety of factors such as appearance, behavior, and personality. First impressions can have a significant impact on one's life and development. In this essay, I will analyze the impact of first impressions on one's life and development and investigate how the impression can be changed. I will also explore the difficulties that people face when attempting to change their first impression and the potential effects on their future.\n",
      "\n",
      "First impressions can be both positive and negative. A positive first impression can lead to further interactions and relationships, while a negative first impression can lead to avoidance and negative interactions. For example, if someone makes a good first impression on a potential employer, they may be more likely to be hired and have a better chance of career success. On the other hand, if someone makes a negative first impression on a potential friend or romantic partner, they may be less likely to have a positive relationship with that person in the future.\n",
      "\n",
      "Changing a first impression can be difficult, as it requires effort and intentionality. It can also be challenging to change someone's first impression if they have a preconceived notion or bias about that person. For example, if someone has always had a negative impression of a particular group of people, it may be difficult to change their first impression of an individual from that group.\n",
      "\n",
      "The difficulties that people face when attempting to change their first impression can have negative effects on their future. If someone is unable to change a negative first impression, they may miss out on opportunities for relationships, career advancement, and personal growth. Additionally, if someone is constantly making negative first impressions on others, they may damage their reputation and relationships.\n",
      "\n",
      "Despite the difficulties, it is important to recognize the importance of first impressions in forming relationships and finding success. First impressions can be a valuable tool for assessing compatibility and potential in relationships, as well as for identifying opportunities for career advancement and personal growth.\n",
      "\n",
      "In conclusion, first impressions can have a significant impact on one's life and development. While changing a first impression can be difficult, it is important to recognize the importance of first impressions in forming relationships and finding success. By being mindful of our first impressions and working to change them when necessary, we can improve our relationships and increase our chances of success in all areas of our lives.\n",
      "        is this text generated by AI?\n",
      "    yes, the text is generated\n",
      ">>>>>>>>>> yes, the text is generated\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        What this story is about is a boy named Luke that helps get animals on and off of the ships that he is one this job is called \"Seagoing Cowboys\". Wha twould you think is hard about this story? not getting sea sick, not falling off the boat, or getting along with the other crew mates? the answer is trying to clean the stalls is my oppinion. All of these things are hard to do, but you can allways go on with life. You try to do the best that you can, but sometimes tou fail ,but you can also succied. His favorite thing to do is to care for animals and he does it in the same way he cares for people. his aunt had a farm and now his childhood farming is starting to pay off the only thing that he never practiced was trying not to get sea sick while he was crossing the Atlantic ocean. He thought that his job was the coolest thing in the world to be doing for his job because he has been doing this since childhood. After all the animals were gone they didn't know what to do. So they played beach games after the stalls were all clean. They played volleyball, baseball, table-tennis tournaments, fencing, boxing, reading, whittling, and the other fun games that made time fly by like a rocket..\n",
      "        is this text generated by AI?\n",
      "    no, the text is written by students\n",
      ">>>>>>>>>> no, the text is written by students\n",
      "tensor(0.1598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        Dear Principal Smith, \n",
      "\n",
      "I am writing to you regarding the cell phone policy options you are considering for our school. After thinking carefully about Policy 1 and Policy 2, I believe that Policy 1 is the better choice. Allowing students to bring phones to school but requiring them to be turned off during class time strikes the right balance.\n",
      "\n",
      "If phones are completely banned as in Policy 2, it may cause more issues than it solves. Students will still try to sneak phones into the school against the rules, which could lead to discipline problems. Additionally, many students rely on their phones after school for important communication with parents about rides home or extracurricular activities. A total ban would prevent this.\n",
      "\n",
      "Policy 1 addresses teachers' concerns about phones being a distraction during lessons by requiring them to be off during class time. However, it still gives students access to phones during free periods like lunch. Many students like to check social media, listen to music, or text friends during these breaks. Denying them phones entirely seems unnecessary.\n",
      "\n",
      "Policy 1 teaches students responsibility by allowing phones if used properly while still in school. They must show they can follow the rules of turning phones off during lessons. This trusting approach to policy encourages maturity from students. \n",
      "\n",
      "In conclusion, I believe Policy 1 strikes the best balance of allowing legitimate phone use while also respecting classroom learning time. It promotes responsibility from students through a sensible, trusting policy. For these reasons, I ask you to choose Policy 1 as the new cell phone policy for our school.\n",
      "\n",
      "Thank you for your consideration.\n",
      "\n",
      "Sincerely,\n",
      "[Your name].\n",
      "        is this text generated by AI?\n",
      "    yes, the text is generated\n",
      ">>>>>>>>>> yes, the text is generated\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "====================================================================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "        read the following text, understand its style and words choices:\n",
      "        Dear, State Senator\n",
      "\n",
      "I am in favor of changing to election by popular vote for the president of the United States. What is the point of voting if the Electoral College decides who wins? Using popular vote means the citizens would actually decide on who would win. Under the electoral college system, voters vote not for the president, but for a state of electors, who in turn elect the president. Who picks the electors in the first place? The single best argument against the electoral college is what we might call the disaster factor. Back in 1960, segregationists in the Louisiana legislature nearly succeeded in replacing the Democratic electors with new electors who would oppose John F. Kennedy. (So that a popular vote for Kennedy would not have actually gone to Kennedy.) At the most basic level, the electoral college is unfair to voters. Because of the winner take all system in each state.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "The Voters    .\n",
      "        is this text generated by AI?\n",
      "     the text is written by students\n",
      ">>>>>>>>>> no, the text is written by students\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    num_epochs = 1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        pbar = tqdm(dataloader_random)\n",
    "        for step, batch_a in enumerate(pbar):\n",
    "            batch,_,final_text,label_text = batch_a\n",
    "            batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            #print(batch)\n",
    "            #outputs = model(batch['input_ids'],labels=batch['labels'])\n",
    "            labels_tensor = batch['labels']\n",
    "            outputs = model(batch['input_ids'])\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            logits = logits[...,:-1,:].contiguous()\n",
    "            labels_tensor = labels_tensor[...,1:].contiguous()\n",
    "            \n",
    "            \n",
    "            #loss = outputs.loss\n",
    "            loss = loss_fn(logits.view(-1, logits.size(-1)), labels_tensor.view(-1))\n",
    "        \n",
    "            total_loss += loss.detach().float()\n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            if(step % 100 == 0):\n",
    "                pbar.set_description(f\"step {step} loss {loss}\")\n",
    "                print(loss)\n",
    "            if(step  % 200 == 0 and step > 0):\n",
    "                from IPython.display import display,clear_output,update_display\n",
    "                test = generate(final_text[0],model,tokenizer)\n",
    "                print(\"=\"* 100)\n",
    "                print(\">\"* 100)\n",
    "                print(test)\n",
    "                print(\">\"* 10,label_text[0])\n",
    "                \n",
    "\n",
    "                \n",
    "            \n",
    "train()           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mËøêË°åÂÖ∑Êúâ‚Äú/usr/bin/python3‚ÄùÁöÑÂçïÂÖÉÊ†ºÈúÄË¶ÅipykernelÂåÖ„ÄÇ\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import time\n",
    "clear_output()\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "for fruit in [1,2,3]:\n",
    "    time.sleep(1)\n",
    "    clear_output()\n",
    "    #out.append_stdout(f\"Do you like {fruit}s?\")\n",
    "    print(fruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mËøêË°åÂÖ∑Êúâ‚Äú/usr/bin/python3‚ÄùÁöÑÂçïÂÖÉÊ†ºÈúÄË¶ÅipykernelÂåÖ„ÄÇ\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#model_trained = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mËøêË°åÂÖ∑Êúâ‚Äú/usr/bin/python3‚ÄùÁöÑÂçïÂÖÉÊ†ºÈúÄË¶ÅipykernelÂåÖ„ÄÇ\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "generate(\"\"\"\n",
    "    read the following text, understand its style and words choices:\n",
    "    maybe its is not rigiht what.\n",
    "    is this text generated by AI?\n",
    "\"\"\",model_trained,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mËøêË°åÂÖ∑Êúâ‚Äú/usr/bin/python3‚ÄùÁöÑÂçïÂÖÉÊ†ºÈúÄË¶ÅipykernelÂåÖ„ÄÇ\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def evaluate(data):\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mËøêË°åÂÖ∑Êúâ‚Äú/usr/bin/python3‚ÄùÁöÑÂçïÂÖÉÊ†ºÈúÄË¶ÅipykernelÂåÖ„ÄÇ\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_data_path = \"./data/test_essays.csv\"\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mËøêË°åÂÖ∑Êúâ‚Äú/usr/bin/python3‚ÄùÁöÑÂçïÂÖÉÊ†ºÈúÄË¶ÅipykernelÂåÖ„ÄÇ\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mËøêË°åÂÖ∑Êúâ‚Äú/usr/bin/python3‚ÄùÁöÑÂçïÂÖÉÊ†ºÈúÄË¶ÅipykernelÂåÖ„ÄÇ\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir =  \"/home/tx/workspace/saved_model\"\n",
    "if(not os.path.exists(save_dir)):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mËøêË°åÂÖ∑Êúâ‚Äú/usr/bin/python3‚ÄùÁöÑÂçïÂÖÉÊ†ºÈúÄË¶ÅipykernelÂåÖ„ÄÇ\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model_save_name = os.path.join(save_dir,'bloom_3b_AI_detector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mËøêË°åÂÖ∑Êúâ‚Äú/usr/bin/python3‚ÄùÁöÑÂçïÂÖÉÊ†ºÈúÄË¶ÅipykernelÂåÖ„ÄÇ\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(model_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mËøêË°åÂÖ∑Êúâ‚Äú/usr/bin/python3‚ÄùÁöÑÂçïÂÖÉÊ†ºÈúÄË¶ÅipykernelÂåÖ„ÄÇ\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
