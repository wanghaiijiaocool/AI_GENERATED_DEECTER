{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_data_path = \"./data/train_essays.csv\"\n",
    "train_prompts_path = \"./data/train_prompts.csv\"\n",
    "supplement_data_dir = \"./data/archive/\"\n",
    "supplement_data_files = [  os.path.join(supplement_data_dir,f)  \n",
    "                          for f in os.listdir(supplement_data_dir)\n",
    "                          if(f.endswith('.csv'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_proxy():\n",
    "    import os\n",
    "    cache_dir = \"/home/tx/workspace/cache\"  # 替换为你想要的缓存目录的路径\n",
    "    os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "    # 代理\n",
    "    os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "    os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "    os.environ['no_proxy'] = '127.0.0.1,localhost'\n",
    "    os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "    os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "    os.environ['NO_PROXY'] = '127.0.0.1,localhost'\n",
    "    return\n",
    "set_proxy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl huggingface.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data=pd.read_csv(train_data_path)\n",
    "train_prompts = pd.read_csv(train_prompts_path)\n",
    "instructions = {\n",
    "    0:train_prompts['instructions'][0],\n",
    "    1:train_prompts['instructions'][1],\n",
    "}\n",
    "\n",
    "train_data['prompt'] = train_data.apply(\n",
    "    lambda r: instructions[r['prompt_id']] if  r['prompt_id'] in instructions else -1,axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>1</td>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>ff669174</td>\n",
       "      <td>0</td>\n",
       "      <td>Limiting car usage has many advantages. Such a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>ffa247e0</td>\n",
       "      <td>0</td>\n",
       "      <td>There's a new trend that has been developing f...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>ffc237e9</td>\n",
       "      <td>0</td>\n",
       "      <td>As we all know cars are a big part of our soci...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>ffe1ca0d</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars have been around since the 1800's and hav...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1378 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1     005db917          0  Transportation is a large necessity in most co...   \n",
       "2     008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3     00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4     00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "...        ...        ...                                                ...   \n",
       "1373  fe6ff9a5          1  There has been a fuss about the Elector Colleg...   \n",
       "1374  ff669174          0  Limiting car usage has many advantages. Such a...   \n",
       "1375  ffa247e0          0  There's a new trend that has been developing f...   \n",
       "1376  ffc237e9          0  As we all know cars are a big part of our soci...   \n",
       "1377  ffe1ca0d          0  Cars have been around since the 1800's and hav...   \n",
       "\n",
       "      generated                                             prompt  \n",
       "0             0  Write an explanatory essay to inform fellow ci...  \n",
       "1             0  Write an explanatory essay to inform fellow ci...  \n",
       "2             0  Write an explanatory essay to inform fellow ci...  \n",
       "3             0  Write an explanatory essay to inform fellow ci...  \n",
       "4             0  Write an explanatory essay to inform fellow ci...  \n",
       "...         ...                                                ...  \n",
       "1373          0  Write a letter to your state senator in which ...  \n",
       "1374          0  Write an explanatory essay to inform fellow ci...  \n",
       "1375          0  Write an explanatory essay to inform fellow ci...  \n",
       "1376          0  Write an explanatory essay to inform fellow ci...  \n",
       "1377          0  Write an explanatory essay to inform fellow ci...  \n",
       "\n",
       "[1378 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "supplement_train_data = pd.concat([\n",
    "    pd.read_csv(f)\n",
    "    for f in supplement_data_files\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>fold</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There are alot reasons to keep our the despise...</td>\n",
       "      <td>0</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Driving smart cars that drive by themself has ...</td>\n",
       "      <td>0</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Principal,\\n\\nI believe that students at ...</td>\n",
       "      <td>0</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Principal,\\n\\nCommunity service should no...</td>\n",
       "      <td>0</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My argument for the development of the driverl...</td>\n",
       "      <td>0</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39780</th>\n",
       "      <td>\"Oh man I didn't make the soccer team!\", yelle...</td>\n",
       "      <td>0</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>F7341069C4A4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39781</th>\n",
       "      <td>I believe that using this technology could be ...</td>\n",
       "      <td>0</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>2</td>\n",
       "      <td>AFE6E553DAC2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39782</th>\n",
       "      <td>The Face on Mars is a fascinating phenomenon t...</td>\n",
       "      <td>1</td>\n",
       "      <td>falcon_180b_v1</td>\n",
       "      <td>2</td>\n",
       "      <td>falcon_180b_v1_600</td>\n",
       "      <td>You have read the article 'Unmasking the Face ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39783</th>\n",
       "      <td>Texting &amp; Driving\\n\\nUsing your phone while dr...</td>\n",
       "      <td>0</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>2</td>\n",
       "      <td>A5F84C104693</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39784</th>\n",
       "      <td>Dear Principal,\\n\\nI have been really good thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>A148C659E98B</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159456 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      There are alot reasons to keep our the despise...      0   \n",
       "1      Driving smart cars that drive by themself has ...      0   \n",
       "2      Dear Principal,\\n\\nI believe that students at ...      0   \n",
       "3      Dear Principal,\\n\\nCommunity service should no...      0   \n",
       "4      My argument for the development of the driverl...      0   \n",
       "...                                                  ...    ...   \n",
       "39780  \"Oh man I didn't make the soccer team!\", yelle...      0   \n",
       "39781  I believe that using this technology could be ...      0   \n",
       "39782  The Face on Mars is a fascinating phenomenon t...      1   \n",
       "39783  Texting & Driving\\n\\nUsing your phone while dr...      0   \n",
       "39784  Dear Principal,\\n\\nI have been really good thi...      0   \n",
       "\n",
       "                source  fold            essay_id  \\\n",
       "0      persuade_corpus     2                 NaN   \n",
       "1      persuade_corpus     4                 NaN   \n",
       "2      persuade_corpus     0                 NaN   \n",
       "3      persuade_corpus     0                 NaN   \n",
       "4      persuade_corpus     3                 NaN   \n",
       "...                ...   ...                 ...   \n",
       "39780  persuade_corpus     4        F7341069C4A4   \n",
       "39781  persuade_corpus     2        AFE6E553DAC2   \n",
       "39782   falcon_180b_v1     2  falcon_180b_v1_600   \n",
       "39783  persuade_corpus     2        A5F84C104693   \n",
       "39784  persuade_corpus     4        A148C659E98B   \n",
       "\n",
       "                                                  prompt  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "3                                                    NaN  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "39780                                                NaN  \n",
       "39781                                                NaN  \n",
       "39782  You have read the article 'Unmasking the Face ...  \n",
       "39783                                                NaN  \n",
       "39784                                                NaN  \n",
       "\n",
       "[159456 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supplement_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplement_train_data['generated'] = supplement_train_data['label']\n",
    "\n",
    "supplement_train_data = supplement_train_data[['text','generated','prompt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As an eighth-grade student, I have noticed tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Studying Science and History at Generic_School...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>As an artist, I am constantly developing and h...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>After conducting extensive research on the eff...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The COVID-19 pandemic has brought about a sign...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39767</th>\n",
       "      <td>Sure thing! Here's my attempt at writing an es...</td>\n",
       "      <td>1</td>\n",
       "      <td>Task: Research why it is beneficial for people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>I think our principal's idea of making us do e...</td>\n",
       "      <td>1</td>\n",
       "      <td>Your principal has decided that all students m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39771</th>\n",
       "      <td>I think it's a good idea for schools to have o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Some schools have implemented policies that al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39778</th>\n",
       "      <td>Advantages of Limiting Car Usage\\n\\nLimiting c...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39782</th>\n",
       "      <td>The Face on Mars is a fascinating phenomenon t...</td>\n",
       "      <td>1</td>\n",
       "      <td>You have read the article 'Unmasking the Face ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44084 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated  \\\n",
       "7      As an eighth-grade student, I have noticed tha...          1   \n",
       "10     Studying Science and History at Generic_School...          1   \n",
       "17     As an artist, I am constantly developing and h...          1   \n",
       "22     After conducting extensive research on the eff...          1   \n",
       "24     The COVID-19 pandemic has brought about a sign...          1   \n",
       "...                                                  ...        ...   \n",
       "39767  Sure thing! Here's my attempt at writing an es...          1   \n",
       "39770  I think our principal's idea of making us do e...          1   \n",
       "39771  I think it's a good idea for schools to have o...          1   \n",
       "39778  Advantages of Limiting Car Usage\\n\\nLimiting c...          1   \n",
       "39782  The Face on Mars is a fascinating phenomenon t...          1   \n",
       "\n",
       "                                                  prompt  \n",
       "7                                                    NaN  \n",
       "10                                                   NaN  \n",
       "17                                                   NaN  \n",
       "22                                                   NaN  \n",
       "24                                                   NaN  \n",
       "...                                                  ...  \n",
       "39767  Task: Research why it is beneficial for people...  \n",
       "39770  Your principal has decided that all students m...  \n",
       "39771  Some schools have implemented policies that al...  \n",
       "39778                                                NaN  \n",
       "39782  You have read the article 'Unmasking the Face ...  \n",
       "\n",
       "[44084 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supplement_train_data[supplement_train_data.generated == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "#del train_data_re\n",
    "gc.collect()\n",
    "train_data_re = pd.DataFrame(train_data[['text','generated','prompt']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_all = pd.concat([train_data,supplement_train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generated\n",
       "0    116747\n",
       "1     44087\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_all.generated.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48ef65f97ec48adbd8ce4977eec330b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "cache_dir = \"/home/tx/workspace/cache\"  # 替换为你想要的缓存目录的路径\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer\n",
    "from transformers import AutoConfig, LlamaConfig \n",
    "# from llava.model.language_model.llava_llama import LlavaLlamaForCausalLM\n",
    "# class LlavaConfig(LlamaConfig):\n",
    "#     model_type = \"llava\"\n",
    "# AutoConfig.register(\"llava\", LlavaConfig)\n",
    "model_name = \"bigscience/bloom-3b\"\n",
    "#model_name = \"ChocoWu/nextgpt_7b_tiva_v0\"#\"liuhaotian/llava-v1.5-7b\"\n",
    "original_model = AutoModelForCausalLM.from_pretrained(model_name,cache_dir=cache_dir,trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,cache_dir=cache_dir)\n",
    "# tokenizer.add_tokens([\"[PAD]\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(prompt,feature_text):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    text= None \n",
    "    if(prompt is not None):\n",
    "        template_with_prompt = f\"\"\"\n",
    "        a prompt is shown as follows: \n",
    "        {prompt}.\n",
    "        text generated by this this prompt is shown as below:\n",
    "        {feature_text}.\n",
    "        is this text generated by AI?\n",
    "        \"\"\"\n",
    "        text = template_with_prompt\n",
    "    else:\n",
    "        template_without_prompt = f\"\"\"\n",
    "        text generated without any prompt is shown as below:\n",
    "        {feature_text}.\n",
    "        is this text generated by AI?\n",
    "        \"\"\"\n",
    "        text = template_without_prompt\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler\n",
    "import torch\n",
    "\n",
    "class myDataset(TensorDataset):\n",
    "\n",
    "    def __init__(self, datalist,max_length=256,tokenizer=None,preprocess_func= None) -> None:\n",
    "        super(myDataset,self).__init__()\n",
    "\n",
    "        if(isinstance(datalist,pd.DataFrame)):\n",
    "            self.datalist = datalist.to_dict(orient='list')\n",
    "        elif(isinstance(datalist,dict)):\n",
    "            self.datalist = datalist\n",
    "        else:\n",
    "            raise Exception(\"错误输入类型\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.preprocess_func = preprocess_func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datalist['text'])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.datalist['text'][index]  \n",
    "        prompt = self.datalist['prompt'][index]  \n",
    "\n",
    "        final_text = self.preprocess_func(prompt,text)\n",
    "        input_ids = self.tokenizer.encode(final_text)\n",
    "        att_mask = [1] * len(input_ids)\n",
    "\n",
    "\n",
    "        labels = None\n",
    "        if('generated' in self.datalist):\n",
    "            generated = self.datalist['generated'][index]\n",
    "            label_text = \" the text is generated by AI\" if generated > 0 else \"the text is written by students\"\n",
    "            label_ids = self.tokenizer.encode(label_text)\n",
    "\n",
    "            labels = [self.tokenizer.eos_token_id]  * len(input_ids)\n",
    "            labels = labels + label_ids\n",
    "            input_ids = input_ids + label_ids   \n",
    "            att_mask = [1] * len(input_ids)\n",
    "        act_len = len(input_ids)\n",
    "        while(len(input_ids) < self.max_length):\n",
    "            input_ids.append(self.tokenizer.eos_token_id)\n",
    "            if(labels is not None):\n",
    "                labels.append(self.tokenizer.eos_token_id)\n",
    "            att_mask.append(0)\n",
    "        input_ids = input_ids[:self.max_length]\n",
    "        labels = labels[:self.max_length]\n",
    "        att_mask = att_mask[:self.max_length]\n",
    "        if(labels is not None):\n",
    "            return {'input_ids':torch.LongTensor(input_ids),'labels':labels,'att_mask':torch.LongTensor(att_mask),'act_len':act_len}\n",
    "        else:\n",
    "            return {'input_ids':torch.LongTensor(input_ids),'att_mask':torch.LongTensor(att_mask)}\n",
    "\n",
    "        \n",
    "dataset = myDataset(datalist=train_data_all,max_length=4096,tokenizer=tokenizer,preprocess_func=generate_prompt) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39780</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Oh man I didn't make the soccer team!\", yelle...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39781</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I believe that using this technology could be ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39782</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Face on Mars is a fascinating phenomenon t...</td>\n",
       "      <td>1</td>\n",
       "      <td>You have read the article 'Unmasking the Face ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39783</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texting &amp; Driving\\n\\nUsing your phone while dr...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39784</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dear Principal,\\n\\nI have been really good thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160834 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  prompt_id                                               text  \\\n",
       "0      0059830c        0.0  Cars. Cars have been around since they became ...   \n",
       "1      005db917        0.0  Transportation is a large necessity in most co...   \n",
       "2      008f63e3        0.0  \"America's love affair with it's vehicles seem...   \n",
       "3      00940276        0.0  How often do you ride in a car? Do you drive a...   \n",
       "4      00c39458        0.0  Cars are a wonderful thing. They are perhaps o...   \n",
       "...         ...        ...                                                ...   \n",
       "39780       NaN        NaN  \"Oh man I didn't make the soccer team!\", yelle...   \n",
       "39781       NaN        NaN  I believe that using this technology could be ...   \n",
       "39782       NaN        NaN  The Face on Mars is a fascinating phenomenon t...   \n",
       "39783       NaN        NaN  Texting & Driving\\n\\nUsing your phone while dr...   \n",
       "39784       NaN        NaN  Dear Principal,\\n\\nI have been really good thi...   \n",
       "\n",
       "       generated                                             prompt  \n",
       "0              0  Write an explanatory essay to inform fellow ci...  \n",
       "1              0  Write an explanatory essay to inform fellow ci...  \n",
       "2              0  Write an explanatory essay to inform fellow ci...  \n",
       "3              0  Write an explanatory essay to inform fellow ci...  \n",
       "4              0  Write an explanatory essay to inform fellow ci...  \n",
       "...          ...                                                ...  \n",
       "39780          0                                                NaN  \n",
       "39781          0                                                NaN  \n",
       "39782          1  You have read the article 'Unmasking the Face ...  \n",
       "39783          0                                                NaN  \n",
       "39784          0                                                NaN  \n",
       "\n",
       "[160834 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_len = [ dataset[i]['act_len'] for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# cnt = 1000000000000\n",
    "# np.percentile(all_len,q=99.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sampler = RandomSampler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader_random = DataLoader(dataset, batch_size=2, sampler=random_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model(input_ids = torch.LongTensor([dataset[0]['input_ids']]),attention_mask=torch.LongTensor([dataset[0]['att_mask']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.04703666202518836\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "from peft import LoraConfig, TaskType\n",
    "lora_target_modules = [\"q_proj\",\"k_proj\",\"v_proj\",'o_proj']\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM, \n",
    "                         inference_mode=False, target_modules=lora_target_modules,\n",
    "                         r=4, lora_alpha=16, lora_dropout=0.1)\n",
    "model = get_peft_model(original_model,peft_config)\n",
    "print(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 23.90 GiB total capacity; 23.38 GiB already allocated; 52.38 MiB free; 23.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/tx/workspace/code_for_compete/AI_GENERATED_DEECTER/ai_detector.ipynb 单元格 29\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.vip.cpolar.cn/home/tx/workspace/code_for_compete/AI_GENERATED_DEECTER/ai_detector.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mcuda()\n",
      "File \u001b[0;32m~/.conda/envs/llava/lib/python3.11/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[0;32m~/.conda/envs/llava/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/llava/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 797 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/llava/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/llava/lib/python3.11/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.conda/envs/llava/lib/python3.11/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 23.90 GiB total capacity; 23.38 GiB already allocated; 52.38 MiB free; 23.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean',ignore_index=tokenizer.pad_token_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(dataloader_random) ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader_random)\n",
    "    for step, batch in enumerate(pbar):\n",
    "        batch = {k: v.cuda() for k, v in batch.items()}\n",
    "        #print(batch)\n",
    "        #outputs = model(batch['input_ids'],labels=batch['labels'])\n",
    "        labels_tensor = batch['labels']\n",
    "        outputs = model(batch['input_ids'])\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        logits = logits[...,:-1,:].contiguous()\n",
    "        labels_tensor = labels_tensor[...,1:].contiguous()\n",
    "        \n",
    "        \n",
    "        #loss = outputs.loss\n",
    "        loss = loss_fn(logits.view(-1, logits.size(-1)), labels_tensor.view(-1))\n",
    "    \n",
    "        total_loss += loss.detach().float()\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if(step % 10 == 0):\n",
    "            pbar.set_description(f\"step {step} loss {loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
